/**
 * AdminStreamContext - PERSISTENT WebRTC Streaming Management
 * 
 * CRITICAL: This context manages WebRTC connections at app level,
 * ensuring streams survive component unmounts and tab switches.
 * 
 * The stream state and peer connections are maintained here,
 * not in any UI component, so they persist regardless of navigation.
 */

import React, { createContext, useContext, useRef, useState, useCallback, useEffect, ReactNode } from 'react';
import { useWebSocket } from './WebSocketContext';
import { useNotification } from './NotificationContext';
import { useAuth } from './AuthContext';

export interface CropSettings {
  enabled: boolean;
  x: number;
  y: number;
  width: number;
  height: number;
}

interface AdminStreamContextType {
  isStreaming: boolean;
  isPaused: boolean;
  isInitializing: boolean;
  isCropReady: boolean; // New: Whether crop is ready and stream can start
  error: string | null;
  startWebRTCScreenShare: () => Promise<void>;
  stopWebRTCScreenShare: () => void;
  pauseStream: () => void;
  resumeStream: () => void;
  screenStream: MediaStream | null;
  originalStream: MediaStream | null; // Original screen share
  croppedStream: MediaStream | null; // Canvas-based cropped stream
  cropSettings: CropSettings | null;
  setCropSettings: (settings: CropSettings | null) => void;
  confirmCropAndStart: () => void; // New: Confirm crop and start broadcasting
  skipCropAndStart: () => void; // New: Skip crop and start with full screen
  // Internal refs for ScreenShareCropper component
  getVideoRef: () => HTMLVideoElement | null;
  getCanvasRef: () => HTMLCanvasElement | null;
}

const AdminStreamContext = createContext<AdminStreamContextType | undefined>(undefined);

export const useAdminStream = () => {
  const context = useContext(AdminStreamContext);
  if (!context) {
    throw new Error('useAdminStream must be used within AdminStreamProvider');
  }
  return context;
};

export const AdminStreamProvider: React.FC<{ children: ReactNode }> = ({ children }) => {
  const [isStreaming, setIsStreaming] = useState(false);
  const [isPaused, setIsPaused] = useState(false);
  const [isInitializing, setIsInitializing] = useState(false);
  const [isCropReady, setIsCropReady] = useState(false); // Crop confirmed or skipped
  const [isBroadcasting, setIsBroadcasting] = useState(false); // Actually broadcasting to players
  const [error, setError] = useState<string | null>(null);
  const { sendWebSocketMessage } = useWebSocket();
  const { showNotification } = useNotification();
  const { state: authState } = useAuth();

  // Refs for core WebRTC objects to persist across re-renders
  const peerConnectionsRef = useRef<Map<string, RTCPeerConnection>>(new Map());
  const originalStreamRef = useRef<MediaStream | null>(null); // Original screen share
  const croppedStreamRef = useRef<MediaStream | null>(null); // Canvas cropped stream
  const streamRef = useRef<MediaStream | null>(null); // Active stream (original or cropped)
  const canvasRef = useRef<HTMLCanvasElement | null>(null);
  const videoRef = useRef<HTMLVideoElement | null>(null);
  const animationFrameRef = useRef<number | null>(null);
  const cropSettingsRef = useRef<CropSettings | null>(null);
  const trackEndedHandlerRef = useRef<(() => void) | null>(null); // ‚úÖ Store handler for cleanup
  const metadataHandlerRef = useRef<(() => void) | null>(null); // ‚úÖ Store handler for cleanup
  const pendingViewersRef = useRef<Set<string>>(new Set()); // ‚úÖ Queue viewers waiting for broadcast
  const streamIdRef = useRef<string>(`stream-${Date.now()}`); // ‚úÖ Unique stream ID for this session
  const retryCountRef = useRef<Map<string, number>>(new Map()); // ‚úÖ Track retry counts per client
  
  const [screenStream, setScreenStream] = useState<MediaStream | null>(null);
  const [originalStream, setOriginalStream] = useState<MediaStream | null>(null);
  const [croppedStream, setCroppedStream] = useState<MediaStream | null>(null);
  const [cropSettings, setCropSettingsState] = useState<CropSettings | null>(null);

  // Cleanup canvas animation frame
  const cleanupCanvas = useCallback(() => {
    if (animationFrameRef.current) {
      cancelAnimationFrame(animationFrameRef.current);
      animationFrameRef.current = null;
    }
    if (canvasRef.current) {
      const canvas = canvasRef.current;
      const ctx = canvas.getContext('2d');
      if (ctx) {
        ctx.clearRect(0, 0, canvas.width, canvas.height);
      }
    }
  }, []);

  const cleanupWebRTC = useCallback(() => {
    console.log('üßπ Cleaning up all WebRTC connections and streams...');

    // ‚úÖ CRITICAL: Cleanup animation frame FIRST
    if (animationFrameRef.current) {
      cancelAnimationFrame(animationFrameRef.current);
      animationFrameRef.current = null;
    }

    // Close all peer connections
    peerConnectionsRef.current.forEach((pc, clientId) => {
      pc.close();
      console.log(`üîå Peer connection closed for client: ${clientId}`);
    });
    peerConnectionsRef.current.clear();

    // Stop all tracks from streams
    if (originalStreamRef.current) {
      originalStreamRef.current.getTracks().forEach(track => {
        // ‚úÖ CRITICAL: Remove event listeners before stopping
        if (trackEndedHandlerRef.current && (track as any)._endedHandler) {
          track.removeEventListener('ended', trackEndedHandlerRef.current);
          delete (track as any)._endedHandler;
        }
        track.stop();
      });
      trackEndedHandlerRef.current = null;
      originalStreamRef.current = null;
    }
    if (croppedStreamRef.current) {
      croppedStreamRef.current.getTracks().forEach(track => track.stop());
      croppedStreamRef.current = null;
    }
    if (streamRef.current) {
      streamRef.current.getTracks().forEach(track => track.stop());
      streamRef.current = null;
    }
    
    // ‚úÖ CRITICAL: Remove video element from memory
    if (videoRef.current) {
      // ‚úÖ CRITICAL: Remove event listeners using stored handlers
      if (metadataHandlerRef.current) {
        videoRef.current.removeEventListener('loadedmetadata', metadataHandlerRef.current);
        metadataHandlerRef.current = null;
      }
      videoRef.current.srcObject = null;
      videoRef.current.removeAttribute('src');
      videoRef.current.load(); // Reset video element
      videoRef.current = null;
    }
    
    // ‚úÖ CRITICAL: Remove canvas element from DOM
    if (canvasRef.current && canvasRef.current.parentNode) {
      // Clear canvas context first
      const ctx = canvasRef.current.getContext('2d');
      if (ctx) {
        ctx.clearRect(0, 0, canvasRef.current.width, canvasRef.current.height);
      }
      // Remove from DOM
      canvasRef.current.parentNode.removeChild(canvasRef.current);
      canvasRef.current = null;
    }
    
    cleanupCanvas();
    
    setScreenStream(null);
    setOriginalStream(null);
    setCroppedStream(null);
    setIsStreaming(false);
    setIsPaused(false);
    setIsInitializing(false);
    setIsCropReady(false);
    setIsBroadcasting(false);
    setError(null);
    pendingViewersRef.current.clear();
    retryCountRef.current.clear();
    streamIdRef.current = `stream-${Date.now()}`; // Reset stream ID
  }, [cleanupCanvas]);

  // Canvas rendering for crop - OPTIMIZED for smooth performance
  useEffect(() => {
    // ‚úÖ CRITICAL: Cancel any existing animation frame first
    if (animationFrameRef.current) {
      cancelAnimationFrame(animationFrameRef.current);
      animationFrameRef.current = null;
    }

    if (!cropSettingsRef.current?.enabled || !originalStreamRef.current || !canvasRef.current || !videoRef.current) {
      cleanupCanvas();
      // If crop disabled, use original stream
      if (originalStreamRef.current) {
        streamRef.current = originalStreamRef.current;
        setScreenStream(originalStreamRef.current);
      }
      return;
    }

    const video = videoRef.current;
    const canvas = canvasRef.current;
    const crop = cropSettingsRef.current;

    // ‚úÖ CRITICAL: Validate crop coordinates against video dimensions
    const validateAndFixCrop = () => {
      if (video.videoWidth === 0 || video.videoHeight === 0) {
        // Video not ready yet, return invalid
        return false;
      }
      
      // Clamp crop to video bounds
      const validCrop = {
        x: Math.max(0, Math.min(crop.x, video.videoWidth - 1)),
        y: Math.max(0, Math.min(crop.y, video.videoHeight - 1)),
        width: Math.min(crop.width, video.videoWidth - crop.x),
        height: Math.min(crop.height, video.videoHeight - crop.y)
      };
      
      // Update crop settings if needed
      if (validCrop.x !== crop.x || validCrop.y !== crop.y || 
          validCrop.width !== crop.width || validCrop.height !== crop.height) {
        console.warn('‚ö†Ô∏è Crop coordinates adjusted to fit video bounds:', {
          original: crop,
          adjusted: validCrop,
          videoSize: { width: video.videoWidth, height: video.videoHeight }
        });
        cropSettingsRef.current = { ...crop, ...validCrop };
      }
      
      // Check if crop is valid
      if (validCrop.width <= 0 || validCrop.height <= 0) {
        console.error('‚ùå Invalid crop dimensions:', validCrop);
        return false;
      }
      
      return true;
    };

    // Set canvas dimensions to crop size (will be validated during draw)
    canvas.width = crop.width;
    canvas.height = crop.height;

    let active = true;
    let lastFrameTime = 0;
    const targetFPS = 30; // Match captureStream FPS
    const frameInterval = 1000 / targetFPS; // ~33ms per frame
    
    // ‚úÖ FIX: Track if first frame is drawn and stream is created
    let firstFrameDrawn = false;
    let streamCreated = false;

    const drawFrame = (currentTime: number) => {
      // ‚úÖ CRITICAL: Check active flag BEFORE requesting next frame
      if (!active) {
        return; // Stop immediately if inactive
      }

      // ‚úÖ OPTIMIZATION: Throttle frame rate to match captureStream
      if (currentTime - lastFrameTime < frameInterval) {
        animationFrameRef.current = requestAnimationFrame(drawFrame);
        return;
      }
      lastFrameTime = currentTime;

      // ‚úÖ CRITICAL: Wait for video to be fully ready and playing
      if (!video || video.videoWidth === 0 || video.videoHeight === 0 || video.readyState < 2) {
        // Video not ready yet, wait
        animationFrameRef.current = requestAnimationFrame(drawFrame);
        return;
      }
      
      // ‚úÖ CRITICAL: Validate crop before drawing
      if (!validateAndFixCrop()) {
        console.warn('‚ö†Ô∏è Crop validation failed, waiting for video...');
        animationFrameRef.current = requestAnimationFrame(drawFrame);
        return;
      }

      const ctx = canvas.getContext('2d', { 
        alpha: false, 
        desynchronized: true // Better performance
      });
      if (!ctx) {
        animationFrameRef.current = requestAnimationFrame(drawFrame);
        return;
      }

      try {
        // ‚úÖ OPTIMIZATION: Use imageSmoothingEnabled for better quality
        ctx.imageSmoothingEnabled = true;
        ctx.imageSmoothingQuality = 'high';
        
        // ‚úÖ Get validated crop (in case it was adjusted)
        const validCrop = cropSettingsRef.current || crop;
        
        // Draw cropped region
        ctx.clearRect(0, 0, canvas.width, canvas.height);
        ctx.drawImage(
          video,
          validCrop.x, validCrop.y, validCrop.width, validCrop.height,
          0, 0, validCrop.width, validCrop.height
        );

        // ‚úÖ FIX: Mark first frame as drawn and verify it has actual content
        if (!firstFrameDrawn) {
          // Verify frame actually has pixels (not just black)
          const sampleData = ctx.getImageData(0, 0, Math.min(10, canvas.width), Math.min(10, canvas.height));
          const hasActualContent = sampleData.data.some((pixel, index) => {
            // Check non-alpha channels (every 4th value starting at 0, 1, 2)
            if (index % 4 < 3) {
              return pixel > 10; // Not pure black (allowing for some noise)
            }
            return false;
          });
          
          if (hasActualContent) {
            firstFrameDrawn = true;
            console.log('‚úÖ First frame with content drawn to canvas');
          } else {
            // Frame is black, wait a bit more
            animationFrameRef.current = requestAnimationFrame(drawFrame);
            return;
          }
        }

        // ‚úÖ CRITICAL: Only request next frame if still active
        if (active) {
          animationFrameRef.current = requestAnimationFrame(drawFrame);
        }
      } catch (err) {
        console.error('‚ùå Canvas draw error:', err);
        // Don't stop on error - might be temporary, just log and continue
        if (active) {
          animationFrameRef.current = requestAnimationFrame(drawFrame);
        }
      }
    };

    // ‚úÖ CRITICAL: Stop old canvas stream before creating new one
    if (croppedStreamRef.current) {
      croppedStreamRef.current.getTracks().forEach(track => track.stop());
      croppedStreamRef.current = null;
      setCroppedStream(null);
      streamCreated = false; // Reset flag
    }

    // ‚úÖ FIX: Create canvas stream ONLY after first frame with content is drawn
    const createStreamAfterFirstFrame = () => {
      // ‚úÖ CRITICAL: Wait for both first frame AND video to be playing
      if (!streamCreated && firstFrameDrawn && video.readyState >= 2 && 
          video.videoWidth > 0 && video.videoHeight > 0) {
        try {
          // ‚úÖ Verify canvas has actual dimensions
          if (canvas.width === 0 || canvas.height === 0) {
            console.warn('‚ö†Ô∏è Canvas dimensions invalid, waiting...');
            if (active) {
              setTimeout(createStreamAfterFirstFrame, 50);
            }
            return;
          }
          
          const canvasStream = canvas.captureStream(targetFPS);
          
          // ‚úÖ Verify stream has tracks
          const tracks = canvasStream.getVideoTracks();
          if (tracks.length === 0) {
            console.warn('‚ö†Ô∏è Canvas stream has no tracks, retrying...');
            if (active) {
              setTimeout(createStreamAfterFirstFrame, 50);
            }
            return;
          }
          
          // ‚úÖ Wait for track to be ready
          const track = tracks[0];
          if (track.readyState === 'ended') {
            console.warn('‚ö†Ô∏è Track ended immediately, retrying...');
            if (active) {
              setTimeout(createStreamAfterFirstFrame, 50);
            }
            return;
          }
          
          croppedStreamRef.current = canvasStream;
          setCroppedStream(canvasStream);
          streamRef.current = canvasStream; // Use cropped stream
          setScreenStream(canvasStream);
          streamCreated = true;
          console.log('‚úÖ Canvas cropped stream created with active track:', {
            trackId: track.id,
            trackState: track.readyState,
            canvasSize: { width: canvas.width, height: canvas.height }
          });
        } catch (err) {
          console.error('‚ùå Failed to create canvas stream:', err);
          if (active) {
            // Retry after delay
            setTimeout(createStreamAfterFirstFrame, 100);
          }
        }
      } else if (!streamCreated && active) {
        // Check again after a short delay if still active
        const reason = !firstFrameDrawn ? 'waiting for first frame' :
                       video.readyState < 2 ? 'video not ready' :
                       video.videoWidth === 0 ? 'video dimensions unknown' : 'unknown';
        if (reason !== 'unknown') {
          // Only log occasionally to avoid spam
          if (Math.random() < 0.1) { // 10% chance
            console.log(`‚è≥ Waiting for stream creation: ${reason}`);
          }
        }
        setTimeout(createStreamAfterFirstFrame, 50);
      }
    };

    // ‚úÖ CRITICAL: Start drawing - wait for video to be ready AND playing
    const startDrawing = () => {
      const checkVideoReady = () => {
        if (video.readyState >= 2 && video.videoWidth > 0 && video.videoHeight > 0) {
          // ‚úÖ Ensure video is playing
          if (video.paused) {
            video.play().catch(err => {
              console.warn('Video play prevented:', err);
              // Continue anyway - user interaction might trigger play
            });
          }
          
          console.log('‚úÖ Video ready, starting canvas rendering:', {
            width: video.videoWidth,
            height: video.videoHeight,
            readyState: video.readyState,
            paused: video.paused
          });
          
          // Start drawing
          animationFrameRef.current = requestAnimationFrame(drawFrame);
          // Start checking for first frame to create stream
          setTimeout(createStreamAfterFirstFrame, 200); // Slightly longer delay to ensure frames
        } else {
          // Not ready yet, wait a bit and check again
          setTimeout(checkVideoReady, 100);
        }
      };
      
      // Wait for metadata
      if (video.readyState >= 1) {
        // Already has some metadata, check if fully ready
        checkVideoReady();
      } else {
        // Wait for metadata first
        video.addEventListener('loadedmetadata', () => {
          checkVideoReady();
        }, { once: true });
      }
    };
    
    startDrawing();

    return () => {
      // ‚úÖ CRITICAL: Stop animation frame FIRST
      active = false;
      firstFrameDrawn = false;
      streamCreated = false;
      if (animationFrameRef.current) {
        cancelAnimationFrame(animationFrameRef.current);
        animationFrameRef.current = null;
      }
      cleanupCanvas();
    };
  }, [cropSettings, cleanupCanvas]);

  const createAndSendOffer = useCallback(async (clientId: string) => {
    console.log('‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ');
    console.log(`üì§ [ADMIN] createAndSendOffer called for ${clientId}`);
    console.log(`üì§ [ADMIN] Time: ${new Date().toISOString()}`);
    
    // Check if we already have a peer connection for this client to avoid duplicates
    if (peerConnectionsRef.current.has(clientId)) {
      console.log(`‚ö†Ô∏è [ADMIN] Peer connection already exists for ${clientId}, skipping creation`);
      console.log('‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ');
      return;
    }
    
    if (!streamRef.current) {
      console.error('‚ùå [ADMIN] Cannot create offer without an active media stream.');
      console.log('‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ');
      return;
    }

    // ‚úÖ CRITICAL: Ensure stream has active video track
    const videoTracks = streamRef.current.getVideoTracks();
    console.log(`üì§ [ADMIN] Video tracks count: ${videoTracks.length}`);
    
    if (videoTracks.length === 0) {
      console.error('‚ùå [ADMIN] Stream has no video tracks.');
      console.log('‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ');
      return;
    }

    // ‚úÖ CRITICAL: Ensure video track is enabled and ready
    const videoTrack = videoTracks[0];
    
    // ‚úÖ CRITICAL FIX #4: Verify track is not muted before creating offer
    if ((videoTrack as any).muted === true) {
      console.error(`‚ùå [ADMIN] CRITICAL: Video track is MUTED for ${clientId}! Cannot create offer.`);
      console.error(`‚ùå [ADMIN] This will cause black screen on player side.`);
      setError(`Video track is muted. Please restart screen share or select different screen/tab.`);
      return;
    }
    
    if (!videoTrack.enabled || videoTrack.readyState !== 'live') {
      // ‚úÖ FIX: Add max retry limit to prevent infinite loops
      const retries = retryCountRef.current.get(clientId) || 0;
      const MAX_RETRIES = 10; // 5 seconds max (10 * 500ms)
      
      if (retries >= MAX_RETRIES) {
        console.error(`‚ùå Max retries reached for ${clientId}. Stream track not ready.`);
        retryCountRef.current.delete(clientId);
        setError(`Failed to connect to viewer ${clientId}. Stream not ready.`);
        return;
      }
      
      retryCountRef.current.set(clientId, retries + 1);
      console.warn(`‚ö†Ô∏è Video track not ready for ${clientId}, retry ${retries + 1}/${MAX_RETRIES}`);
      
      // Wait a bit and retry
      setTimeout(() => {
        if (isBroadcasting && streamRef.current && streamRef.current.getVideoTracks().length > 0) {
          const retryTrack = streamRef.current.getVideoTracks()[0];
          // ‚úÖ CRITICAL: Also check if retry track is muted
          if ((retryTrack as any).muted === true) {
            console.error(`‚ùå [ADMIN] Retry track is still MUTED. Cannot proceed.`);
            setError(`Video track is muted. Please restart screen share.`);
            retryCountRef.current.delete(clientId);
            return;
          }
          if (retryTrack.enabled && retryTrack.readyState === 'live') {
            retryCountRef.current.delete(clientId); // Reset on success
            createAndSendOffer(clientId);
          } else {
            createAndSendOffer(clientId); // Retry again
          }
        }
      }, 500);
      return;
    }
    
    // ‚úÖ Success - clear retry count
    retryCountRef.current.delete(clientId);

    console.log(`üöÄ Creating new peer connection and offer for client: ${clientId}`);
    
    const pc = new RTCPeerConnection({
      iceServers: [
        { urls: 'stun:stun.l.google.com:19302' },
        { urls: 'stun:stun1.l.google.com:19302' },
        {
          urls: 'turn:openrelay.metered.ca:80',
          username: 'openrelayproject',
          credential: 'openrelayproject'
        },
        {
          urls: 'turn:openrelay.metered.ca:443',
          username: 'openrelayproject',
          credential: 'openrelayproject'
        }
      ],
      iceTransportPolicy: 'all',
      bundlePolicy: 'max-bundle',
      rtcpMuxPolicy: 'require'
    });

    peerConnectionsRef.current.set(clientId, pc);

    pc.onicecandidate = (event) => {
      if (event.candidate) {
        console.log(`üßä Sending ICE candidate to client: ${clientId}`);
        sendWebSocketMessage({
          type: 'webrtc:signal',
          data: {
            type: 'ice-candidate',
            to: clientId,
            from: authState.user?.id,
            candidate: event.candidate,
          },
        });
      }
    };

    pc.onconnectionstatechange = () => {
      const state = pc.connectionState;
      console.log(`üîå ADMIN WebRTC Connection State for ${clientId}: ${state}`);
      
      if (state === 'failed' || state === 'closed') {
        console.error(`‚ùå ADMIN WebRTC connection failed for ${clientId}.`);
        
        // ‚úÖ CRITICAL: Log track states when connection fails
        const transceivers = pc.getTransceivers();
        transceivers.forEach((t, idx) => {
          console.error(`‚ùå [ADMIN] Transceiver ${idx} state:`, {
            mid: t.mid,
            direction: t.direction,
            currentDirection: t.currentDirection,
            senderTrackId: t.sender?.track?.id,
            senderTrackEnabled: t.sender?.track?.enabled,
            senderTrackState: t.sender?.track?.readyState,
            senderTrackMuted: (t.sender?.track as any)?.muted
          });
        });
        
        pc.close();
        peerConnectionsRef.current.delete(clientId);
      } else if (state === 'connected') {
        console.log(`‚úÖ ADMIN WebRTC connection established with ${clientId}!`);
        
        // ‚úÖ CRITICAL: Verify tracks are still active after connection
        const transceivers = pc.getTransceivers();
        transceivers.forEach((t, idx) => {
          const track = t.sender?.track;
          if (track) {
            console.log(`‚úÖ [ADMIN] Transceiver ${idx} track state after connection:`, {
              trackId: track.id,
              enabled: track.enabled,
              readyState: track.readyState,
              muted: (track as any).muted,
              kind: track.kind
            });
            
            // Warn if track is muted or not enabled
            if (!track.enabled) {
              console.warn(`‚ö†Ô∏è [ADMIN] WARNING: Track ${track.kind} is DISABLED after connection!`);
            }
            if ((track as any).muted === true) {
              console.warn(`‚ö†Ô∏è [ADMIN] WARNING: Track ${track.kind} is MUTED after connection! No frames will be sent.`);
            }
          }
        });
      }
    };
    
    // Add stream tracks to the peer connection
    const tracks = streamRef.current.getTracks();
    console.log(`üìπ Adding ${tracks.length} tracks to peer connection for ${clientId}:`, {
      videoTracks: tracks.filter(t => t.kind === 'video').length,
      audioTracks: tracks.filter(t => t.kind === 'audio').length,
      trackStates: tracks.map(t => ({ kind: t.kind, enabled: t.enabled, readyState: t.readyState }))
    });
    
    try {
      // ‚úÖ CRITICAL: Add tracks to the peer connection and verify they're producing frames
      tracks.forEach(track => {
        // ‚úÖ FIX: Ensure track is enabled and not muted before adding
        if (!track.enabled) {
          console.warn(`‚ö†Ô∏è [ADMIN] Track ${track.kind} is disabled, enabling...`);
          track.enabled = true;
        }
        
        // ‚úÖ CRITICAL FIX #4: STRICT validation - don't add muted tracks - they won't send frames
        if ((track as any).muted === true) {
          console.error('‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ');
          console.error(`‚ùå [ADMIN] CRITICAL: Track ${track.kind} is MUTED! Cannot add to peer connection.`);
          console.error(`‚ùå [ADMIN] This is the root cause of black screen on player side.`);
          console.error(`‚ùå [ADMIN] Track muted state:`, {
            muted: (track as any).muted,
            enabled: track.enabled,
            readyState: track.readyState,
            trackId: track.id
          });
          console.error(`‚ùå [ADMIN] CLOSING peer connection for ${clientId} - muted track detected.`);
          console.error('‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ');
          // ‚úÖ CRITICAL: Don't add muted tracks - close connection and show error
          setError(`‚ùå CRITICAL: Track ${track.kind} is muted. Connection to ${clientId} blocked. Please restart screen share.`);
          pc.close();
          peerConnectionsRef.current.delete(clientId);
          // ‚úÖ CRITICAL: Stop broadcasting if any track is muted
          setIsBroadcasting(false);
          throw new Error(`Cannot add muted ${track.kind} track to peer connection - connection blocked`);
        } else {
          console.log(`‚úÖ [ADMIN] Track ${track.kind} is NOT muted - ready to add to peer connection`);
        }
        
        // ‚úÖ CRITICAL FIX #1: Continuous track monitoring with enhanced mute detection
        let muteCheckInterval: NodeJS.Timeout | null = null;
        
        const checkMuteState = () => {
          if ((track as any).muted === true) {
            console.error('‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ');
            console.error(`‚ùå [ADMIN] CRITICAL: Track ${track.kind} is MUTED!`);
            console.error(`‚ùå [ADMIN] Connection to ${clientId} will show black screen.`);
            console.error(`‚ùå [ADMIN] Track state:`, {
              enabled: track.enabled,
              readyState: track.readyState,
              muted: (track as any).muted,
              trackId: track.id
            });
            console.error(`‚ùå [ADMIN] Closing connection and stopping broadcast.`);
            console.error('‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ');
            
            // Stop monitoring
            if (muteCheckInterval) {
              clearInterval(muteCheckInterval);
              muteCheckInterval = null;
            }
            
            setIsBroadcasting(false);
            setError(`‚ùå Track ${track.kind} became muted. Broadcast stopped. Please restart screen share.`);
            pc.close();
            peerConnectionsRef.current.delete(clientId);
            return true; // Track is muted
          }
          return false; // Track is not muted
        };
        
        // ‚úÖ CRITICAL: Check immediately and set up continuous monitoring
        checkMuteState();
        
        // ‚úÖ ENHANCED: Monitor for mute events AND check periodically
        const muteHandler = () => {
          console.error(`‚ùå [ADMIN] CRITICAL: Track ${track.kind} mute event fired!`);
          checkMuteState();
        };
        
        track.addEventListener('mute', muteHandler);
        
        // ‚úÖ NEW: Continuous monitoring - check every 2 seconds for 60 seconds (30 checks)
        let checkCount = 0;
        muteCheckInterval = setInterval(() => {
          checkCount++;
          const isMuted = checkMuteState();
          
          if (isMuted) {
            // Track is muted - interval will be cleared in checkMuteState
            return;
          }
          
          // Log progress every 10 checks (every 20 seconds)
          if (checkCount % 10 === 0) {
            console.log(`‚úÖ [ADMIN] Track ${track.kind} still healthy after ${checkCount * 2} seconds`);
          }
          
          // Stop monitoring after 60 seconds (30 checks)
          if (checkCount >= 30) {
            console.log(`‚úÖ [ADMIN] Track ${track.kind} monitoring complete - track is healthy`);
            if (muteCheckInterval) {
              clearInterval(muteCheckInterval);
              muteCheckInterval = null;
            }
          }
        }, 2000);
        
        // ‚úÖ CRITICAL: Clean up interval when connection closes
        pc.addEventListener('connectionstatechange', () => {
          if (pc.connectionState === 'closed' || pc.connectionState === 'failed') {
            if (muteCheckInterval) {
              clearInterval(muteCheckInterval);
              muteCheckInterval = null;
            }
            track.removeEventListener('mute', muteHandler);
          }
        });
        
        // ‚úÖ CRITICAL: Add track to peer connection only if not muted
        pc.addTrack(track, streamRef.current!);
        console.log(`‚úÖ Added ${track.kind} track:`, {
          trackId: track.id,
          enabled: track.enabled,
          readyState: track.readyState,
          muted: (track as any).muted,
          kind: track.kind,
          label: track.label,
          settings: track.getSettings ? track.getSettings() : 'N/A'
        });
        
        // ‚úÖ CRITICAL: Add event listeners to track to verify it's working
        track.addEventListener('ended', () => {
          console.error(`‚ùå [ADMIN] Track ${track.kind} ended for client ${clientId}!`);
        }, { once: true });
        
        track.addEventListener('mute', () => {
          console.warn(`‚ö†Ô∏è [ADMIN] Track ${track.kind} muted for client ${clientId}!`);
        }, { once: true });
        
        track.addEventListener('unmute', () => {
          console.log(`‚úÖ [ADMIN] Track ${track.kind} unmuted for client ${clientId}`);
        }, { once: true });
      });
      
      // ‚úÖ CRITICAL: Log transceivers to verify tracks are properly added
      const transceivers = pc.getTransceivers();
      console.log(`üì° [ADMIN] Peer connection transceivers for ${clientId}:`, {
        transceiverCount: transceivers.length,
        transceivers: transceivers.map((t, idx) => ({
          index: idx,
          mid: t.mid,
          kind: t.sender?.track?.kind || t.receiver?.track?.kind || 'unknown',
          direction: t.direction,
          currentDirection: t.currentDirection,
          senderTrackId: t.sender?.track?.id,
          senderTrackEnabled: t.sender?.track?.enabled,
          senderTrackState: t.sender?.track?.readyState
        }))
      });
    } catch (trackError) {
      console.error('‚ùå Error adding tracks to peer connection:', trackError);
      // Clean up the peer connection if adding tracks failed
      pc.close();
      peerConnectionsRef.current.delete(clientId);
      setError(`Failed to add tracks to connection for ${clientId}.`);
      return;
    }

    try {
      console.log(`üì§ [ADMIN] Creating offer for ${clientId}...`);
      
      // ‚úÖ CRITICAL FIX #4: FINAL validation RIGHT BEFORE creating offer
      // This is the LAST chance to catch muted tracks before sending offer
      const tracksBeforeOffer = streamRef.current?.getVideoTracks() || [];
      const videoTrackBeforeOffer = tracksBeforeOffer[0];
      
      if (!videoTrackBeforeOffer) {
        console.error(`‚ùå [ADMIN] CRITICAL: No video track found right before creating offer for ${clientId}!`);
        setError(`No video track available for ${clientId}. Please restart screen share.`);
        pc.close();
        peerConnectionsRef.current.delete(clientId);
        return;
      }
      
      if ((videoTrackBeforeOffer as any).muted === true) {
        console.error('‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ');
        console.error(`‚ùå [ADMIN] CRITICAL: Track is MUTED RIGHT BEFORE creating offer for ${clientId}! BLOCKING.`);
        console.error('‚ùå [ADMIN] Track was muted between adding to peer connection and creating offer.');
        console.error('‚ùå [ADMIN] Track state:', {
          enabled: videoTrackBeforeOffer.enabled,
          readyState: videoTrackBeforeOffer.readyState,
          muted: (videoTrackBeforeOffer as any).muted,
          trackId: videoTrackBeforeOffer.id
        });
        console.error('‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ');
        setIsBroadcasting(false);
        setError(`‚ùå OFFER BLOCKED: Video track is muted for ${clientId}. Please restart screen share.`);
        pc.close();
        peerConnectionsRef.current.delete(clientId);
        return;
      }
      
      if (!videoTrackBeforeOffer.enabled || videoTrackBeforeOffer.readyState !== 'live') {
        console.error(`‚ùå [ADMIN] CRITICAL: Track not ready right before creating offer for ${clientId}!`);
        console.error('‚ùå [ADMIN] Track state:', {
          enabled: videoTrackBeforeOffer.enabled,
          readyState: videoTrackBeforeOffer.readyState,
          muted: (videoTrackBeforeOffer as any).muted
        });
        setIsBroadcasting(false);
        setError(`Video track not ready for ${clientId}. Please restart screen share.`);
        pc.close();
        peerConnectionsRef.current.delete(clientId);
        return;
      }
      
      // ‚úÖ Also check tracks already added to peer connection
      const transceiversBeforeOffer = pc.getTransceivers();
      for (const transceiver of transceiversBeforeOffer) {
        const senderTrack = transceiver.sender?.track;
        if (senderTrack && senderTrack.kind === 'video') {
          if ((senderTrack as any).muted === true) {
            console.error('‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ');
            console.error(`‚ùå [ADMIN] CRITICAL: Track in peer connection is MUTED for ${clientId}! BLOCKING.`);
            console.error('‚ùå [ADMIN] Track in transceiver is muted - cannot send frames.');
            console.error('‚ùå [ADMIN] Track state:', {
              enabled: senderTrack.enabled,
              readyState: senderTrack.readyState,
              muted: (senderTrack as any).muted,
              trackId: senderTrack.id
            });
            console.error('‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ');
            setIsBroadcasting(false);
            setError(`‚ùå OFFER BLOCKED: Track in peer connection is muted for ${clientId}. Please restart screen share.`);
            pc.close();
            peerConnectionsRef.current.delete(clientId);
            return;
          }
        }
      }
      
      console.log(`‚úÖ [ADMIN] FINAL validation passed - track is ready and unmuted before creating offer for ${clientId}:`, {
        enabled: videoTrackBeforeOffer.enabled,
        readyState: videoTrackBeforeOffer.readyState,
        muted: (videoTrackBeforeOffer as any).muted,
        trackId: videoTrackBeforeOffer.id,
        transceivers: transceiversBeforeOffer.length
      });
      
      // ‚úÖ CRITICAL: Create offer with proper video encoding constraints
      // This ensures frames are actually encoded and sent
      const offer = await pc.createOffer({
        offerToReceiveVideo: false, // We're sending video, not receiving
        offerToReceiveAudio: false  // No audio
      });
      
      // ‚úÖ CRITICAL: Set proper codec preferences if possible
      // This helps ensure compatibility and frame transmission
      await pc.setLocalDescription(offer);
      
      // ‚úÖ CRITICAL: Verify transceivers are configured correctly after setting description
      const transceivers = pc.getTransceivers();
      transceivers.forEach((transceiver, idx) => {
        const track = transceiver.sender?.track;
        if (track && track.kind === 'video') {
          console.log(`‚úÖ [ADMIN] Transceiver ${idx} (video) configuration:`, {
            mid: transceiver.mid,
            direction: transceiver.direction,
            currentDirection: transceiver.currentDirection,
            trackId: track.id,
            trackEnabled: track.enabled,
            trackMuted: (track as any).muted,
            trackReadyState: track.readyState
          });
        }
      });

      console.log(`‚¨ÜÔ∏è [ADMIN] Sending offer to client: ${clientId}`);
      console.log(`‚¨ÜÔ∏è [ADMIN] Offer type: ${offer.type}, SDP length: ${offer.sdp?.length || 0} chars`);
      console.log(`‚¨ÜÔ∏è [ADMIN] Offer SDP (first 200 chars): ${offer.sdp?.substring(0, 200)}`);
      // ‚úÖ FIX: Send full RTCSessionDescriptionInit object, not just SDP string
      sendWebSocketMessage({
        type: 'webrtc:signal',
        data: {
          type: 'offer',
          to: clientId,
          from: authState.user?.id,
          sdp: offer, // Send full RTCSessionDescriptionInit object
        },
      });
      console.log(`‚úÖ [ADMIN] Offer sent successfully to ${clientId}`);
      console.log('‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ');
    } catch (err) {
      console.error(`‚ùå [ADMIN] Failed to create or send offer to ${clientId}:`, err);
      // Clean up the peer connection if offer creation failed
      pc.close();
      peerConnectionsRef.current.delete(clientId);
      console.log('‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ');
      setError(`Failed to create offer for ${clientId}.`);
    }
  }, [sendWebSocketMessage, authState.user?.id, isBroadcasting]);
  
  const setCropSettings = useCallback((settings: CropSettings | null) => {
    cropSettingsRef.current = settings;
    setCropSettingsState(settings);
    
    // Update active stream based on crop settings
    if (settings?.enabled && croppedStreamRef.current) {
      streamRef.current = croppedStreamRef.current;
      setScreenStream(croppedStreamRef.current);
    } else if (originalStreamRef.current) {
      streamRef.current = originalStreamRef.current;
      setScreenStream(originalStreamRef.current);
    }
  }, []);

  // Confirm crop and start broadcasting to players
  const confirmCropAndStart = useCallback(() => {
    console.log('‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ');
    console.log('[LOG] confirmCropAndStart called');
    if (!isStreaming || !streamRef.current) {
      setError('Please start screen share first');
      return;
    }

    if (videoRef.current && videoRef.current.readyState < 2) {
      setError('Video not ready yet. Please wait...');
      return;
    }

    // ‚úÖ FIX: Enhanced stream readiness check
    const activeStream = cropSettingsRef.current?.enabled ? croppedStreamRef.current : streamRef.current;
    if (!activeStream) {
      setError('Stream not available. Please wait...');
      return;
    }

    const videoTracks = activeStream.getVideoTracks();
    if (videoTracks.length === 0) {
      setError('Stream has no video tracks. Please wait...');
      return;
    }

    const videoTrack = videoTracks[0];
    
    // ‚úÖ CRITICAL FIX #3: STRICT validation - block muted tracks before broadcasting
    if ((videoTrack as any).muted === true) {
      console.error('‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ');
      console.error('‚ùå [ADMIN] CRITICAL: Video track is MUTED! BLOCKING broadcast.');
      console.error('‚ùå [ADMIN] This will cause black screen on ALL players.');
      console.error('‚ùå [ADMIN] Tracks CANNOT be unmuted - must restart screen share.');
      console.error('‚ùå [ADMIN] Track state:', {
        enabled: videoTrack.enabled,
        readyState: videoTrack.readyState,
        muted: (videoTrack as any).muted,
        trackId: videoTrack.id
      });
      console.error('‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ');
      setIsBroadcasting(false);
      setError('‚ùå BROADCAST BLOCKED: Video track is muted. This will cause black screen for all players. Please restart screen share or select a different screen/tab.');
      return; // ‚úÖ CRITICAL: Don't broadcast muted track
    }
    
    // ‚úÖ CRITICAL: Double-check track is enabled and live
    if (!videoTrack.enabled) {
      console.warn('‚ö†Ô∏è [ADMIN] Video track is disabled, enabling...');
      videoTrack.enabled = true;
      // Re-check after enabling
      if ((videoTrack as any).muted === true) {
        console.error('‚ùå [ADMIN] Track still muted after enabling. BLOCKING broadcast.');
        setIsBroadcasting(false);
        setError('Video track is muted. Please restart screen share.');
        return;
      }
    }
    
    if (videoTrack.readyState !== 'live') {
      setError('Stream track is not live yet. Please wait...');
      return;
    }

    if (cropSettingsRef.current?.enabled) {
      if (!croppedStreamRef.current || croppedStreamRef.current.getVideoTracks().length === 0 || croppedStreamRef.current.getVideoTracks()[0].readyState !== 'live') {
        setError('Crop stream not ready yet. Please wait a moment and try again.');
        return;
      }
    }

    console.log('‚úÖ Stream readiness verified:', {
      hasStream: !!activeStream,
      videoTracks: videoTracks.length,
      trackState: videoTrack.readyState,
      trackEnabled: videoTrack.enabled,
      streamId: streamIdRef.current
    });

    setIsCropReady(true);
    setIsBroadcasting(true);

    console.log('‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ');
    console.log('[LOG] Sending stream-start message');
    console.log('[LOG] StreamId:', streamIdRef.current);
    console.log('[LOG] Admin ID:', authState.user?.id);
    console.log('[LOG] Stream ready:', {
      hasStream: !!streamRef.current,
      videoTracks: streamRef.current?.getVideoTracks().length || 0,
      trackStates: streamRef.current?.getVideoTracks().map(t => ({
        enabled: t.enabled,
        readyState: t.readyState,
        muted: (t as any).muted
      })) || []
    });
    
    const message = {
      type: 'webrtc:signal' as const,
      data: {
        type: 'stream-start' as const,
        from: authState.user?.id,
        streamId: streamIdRef.current,
      },
    };
    
    console.log('[LOG] Full message being sent:', JSON.stringify(message, null, 2));
    console.log('[LOG] sendWebSocketMessage function:', typeof sendWebSocketMessage);
    console.log('‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ');
    
    // ‚úÖ CRITICAL FIX #3: FINAL validation RIGHT BEFORE sending stream-start
    // This is the LAST chance to catch muted tracks before broadcasting starts
    const finalVideoTrack = activeStream.getVideoTracks()[0];
    if (!finalVideoTrack) {
      console.error('‚ùå [ADMIN] CRITICAL: No video track found right before broadcast!');
      setError('No video track available. Please restart screen share.');
      setIsBroadcasting(false);
      return;
    }
    
    if ((finalVideoTrack as any).muted === true) {
      console.error('‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ');
      console.error('‚ùå [ADMIN] CRITICAL: Track is MUTED RIGHT BEFORE broadcast! BLOCKING.');
      console.error('‚ùå [ADMIN] Track was muted between validation and broadcast start.');
      console.error('‚ùå [ADMIN] Track state:', {
        enabled: finalVideoTrack.enabled,
        readyState: finalVideoTrack.readyState,
        muted: (finalVideoTrack as any).muted,
        trackId: finalVideoTrack.id
      });
      console.error('‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ');
      setIsBroadcasting(false);
      setError('‚ùå BROADCAST BLOCKED: Video track became muted. Please restart screen share.');
      return;
    }
    
    if (!finalVideoTrack.enabled || finalVideoTrack.readyState !== 'live') {
      console.error('‚ùå [ADMIN] CRITICAL: Track not ready right before broadcast!');
      console.error('‚ùå [ADMIN] Track state:', {
        enabled: finalVideoTrack.enabled,
        readyState: finalVideoTrack.readyState,
        muted: (finalVideoTrack as any).muted
      });
      setIsBroadcasting(false);
      setError('Video track not ready. Please restart screen share.');
      return;
    }
    
    console.log('‚úÖ [ADMIN] FINAL validation passed - track is ready and unmuted:', {
      enabled: finalVideoTrack.enabled,
      readyState: finalVideoTrack.readyState,
      muted: (finalVideoTrack as any).muted,
      trackId: finalVideoTrack.id
    });
    
    try {
      sendWebSocketMessage(message);
      console.log('[LOG] ‚úÖ stream-start message sent successfully via sendWebSocketMessage');
    } catch (error) {
      console.error('[LOG] ‚ùå Error sending stream-start message:', error);
    }

    if (pendingViewersRef.current.size > 0) {
      console.log(`[LOG] Processing ${pendingViewersRef.current.size} pending viewers`);
      const pending = Array.from(pendingViewersRef.current);
      pendingViewersRef.current.clear();
      
      pending.forEach((clientId, index) => {
        setTimeout(() => {
          if (streamRef.current && streamRef.current.getVideoTracks().length > 0) {
            createAndSendOffer(clientId);
          } else {
            pendingViewersRef.current.add(clientId);
          }
        }, 100 * (index + 1));
      });
    }

    showNotification('‚úÖ Streaming started! Players can now see your stream.', 'success');
  }, [isStreaming, sendWebSocketMessage, authState.user?.id, showNotification, createAndSendOffer]);

  const skipCropAndStart = useCallback(() => {
    console.log('‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ');
    console.log('[LOG] skipCropAndStart called');
    if (!isStreaming || !originalStreamRef.current) {
      setError('Please start screen share first');
      return;
    }

    setCropSettings(null);
    streamRef.current = originalStreamRef.current;
    setScreenStream(originalStreamRef.current);

    // ‚úÖ FIX: Enhanced stream readiness check with retry
    const checkStreamReady = () => {
      const stream = streamRef.current;
      if (!stream) {
        console.warn('‚ö†Ô∏è Stream not available yet, retrying...');
        setTimeout(checkStreamReady, 100);
        return;
      }

      const videoTracks = stream.getVideoTracks();
      if (videoTracks.length === 0) {
        console.warn('‚ö†Ô∏è Stream has no video tracks yet, retrying...');
        setTimeout(checkStreamReady, 100);
        return;
      }

      const videoTrack = videoTracks[0];
      if (videoTrack.readyState !== 'live') {
        console.warn('‚ö†Ô∏è Video track not live yet, retrying...');
        setTimeout(checkStreamReady, 100);
        return;
      }

      // ‚úÖ FIX: Also check video element readiness
      if (videoRef.current && videoRef.current.readyState < 2) {
        console.warn('‚ö†Ô∏è Video element not ready yet, retrying...');
        setTimeout(checkStreamReady, 100);
        return;
      }

      console.log('‚úÖ Stream readiness verified:', {
        hasStream: !!stream,
        videoTracks: videoTracks.length,
        trackState: videoTrack.readyState,
        trackEnabled: videoTrack.enabled,
        streamId: streamIdRef.current
      });

      setIsCropReady(true);
      setIsBroadcasting(true);

      console.log('‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ');
      console.log('[LOG] Sending stream-start message (skipped crop)');
      console.log('[LOG] StreamId:', streamIdRef.current);
      console.log('[LOG] Admin ID:', authState.user?.id);
      console.log('[LOG] Stream ready:', {
        hasStream: !!streamRef.current,
        videoTracks: streamRef.current?.getVideoTracks().length || 0,
        trackStates: streamRef.current?.getVideoTracks().map(t => ({
          enabled: t.enabled,
          readyState: t.readyState,
          muted: (t as any).muted
        })) || []
      });
      
      const message = {
        type: 'webrtc:signal' as const,
        data: {
          type: 'stream-start' as const,
          from: authState.user?.id,
          streamId: streamIdRef.current,
        },
      };
      
      console.log('[LOG] Full message being sent:', JSON.stringify(message, null, 2));
      console.log('[LOG] sendWebSocketMessage function:', typeof sendWebSocketMessage);
      console.log('‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ');
      
      try {
        sendWebSocketMessage(message);
        console.log('[LOG] ‚úÖ stream-start message sent successfully via sendWebSocketMessage (skipped crop)');
      } catch (error) {
        console.error('[LOG] ‚ùå Error sending stream-start message:', error);
      }

      showNotification('‚úÖ Streaming started! Players can now see your stream.', 'success');
    };

    // Start checking immediately
    checkStreamReady();
  }, [isStreaming, sendWebSocketMessage, authState.user?.id, showNotification, setCropSettings]);

  const startWebRTCScreenShare = useCallback(async () => {
    console.log('[LOG] startWebRTCScreenShare called');
    if (isStreaming || isInitializing) {
      console.warn('‚ö†Ô∏è Stream already in progress.');
      return;
    }
    
    console.log('üé¨ Starting WebRTC screen share...');
    setIsInitializing(true);
    setError(null);
    
    try {
      const stream = await navigator.mediaDevices.getDisplayMedia({
        video: {
          width: { ideal: 1920, max: 1920 },
          height: { ideal: 1080, max: 1080 },
          frameRate: { ideal: 30, max: 60 },
          cursor: 'always',
        } as MediaTrackConstraints & { cursor?: 'always' | 'never' | 'motion' },
        audio: false,
      });
      console.log('[LOG] getDisplayMedia success, stream:', stream);
      
      // ‚úÖ CRITICAL FIX #1: Ensure all tracks are enabled and NOT muted
      const tracks = stream.getTracks();
      console.log('üìπ [ADMIN] Stream tracks captured:', tracks.length);
      
      // ‚úÖ CRITICAL FIX: Check for muted tracks BEFORE setting stream
      let hasMutedTrack = false;
      const mutedTracks: MediaStreamTrack[] = [];
      
      tracks.forEach((track, idx) => {
        console.log(`üìπ [ADMIN] Track ${idx} initial state:`, {
          kind: track.kind,
          enabled: track.enabled,
          readyState: track.readyState,
          muted: (track as any).muted,
          trackId: track.id
        });
        
        // ‚úÖ CRITICAL: Enable track if disabled
        if (!track.enabled) {
          console.warn(`‚ö†Ô∏è [ADMIN] Track ${idx} (${track.kind}) is disabled, enabling...`);
          track.enabled = true;
        }
        
        // ‚úÖ CRITICAL FIX #2: BLOCK muted tracks - this is the ROOT CAUSE of black screen
        if ((track as any).muted === true) {
          console.error(`‚ùå [ADMIN] CRITICAL: Track ${idx} (${track.kind}) is MUTED at source!`);
          console.error(`‚ùå [ADMIN] This will cause black screen on player side.`);
          console.error(`‚ùå [ADMIN] BLOCKING: Cannot proceed with muted track.`);
          hasMutedTrack = true;
          mutedTracks.push(track);
        } else {
          console.log(`‚úÖ [ADMIN] Track ${idx} (${track.kind}) is NOT muted - ready to send frames.`);
        }
        
        // ‚úÖ CRITICAL: Monitor track state changes
        track.addEventListener('mute', () => {
          console.error(`‚ùå [ADMIN] CRITICAL: Track ${idx} (${track.kind}) was MUTED after capture!`);
          console.error(`‚ùå [ADMIN] This will cause black screen. Stop screen share immediately.`);
          // ‚úÖ CRITICAL: If track gets muted after capture, stop streaming and show error
          setIsStreaming(false);
          setError('Video track was muted. Please restart screen share.');
          // Stop all tracks
          stream.getTracks().forEach(t => t.stop());
          originalStreamRef.current = null;
          streamRef.current = null;
          setOriginalStream(null);
          setScreenStream(null);
        });
        
        track.addEventListener('unmute', () => {
          console.log(`‚úÖ [ADMIN] Track ${idx} (${track.kind}) was unmuted.`);
        });
      });
      
      // ‚úÖ CRITICAL FIX: STOP if any track is muted - don't proceed with muted tracks
      if (hasMutedTrack) {
        console.error('‚ùå [ADMIN] CRITICAL: BLOCKING screen share - muted tracks detected!');
        console.error('‚ùå [ADMIN] Muted tracks:', mutedTracks.map(t => ({ kind: t.kind, id: t.id })));
        // Stop all tracks
        stream.getTracks().forEach(track => track.stop());
        setError('Screen share blocked: Video track is muted. Please restart screen share or select a different screen/tab. This is usually caused by browser or OS settings that prevent screen sharing.');
        setIsStreaming(false);
        setOriginalStream(null);
        setScreenStream(null);
        originalStreamRef.current = null;
        streamRef.current = null;
        return; // ‚úÖ CRITICAL: Don't proceed with muted track
      }
      
      originalStreamRef.current = stream;
      setOriginalStream(stream);
      
      if (videoRef.current) {
        if (metadataHandlerRef.current) {
          videoRef.current.removeEventListener('loadedmetadata', metadataHandlerRef.current);
        }
        videoRef.current.srcObject = null;
      }
      
      if (!videoRef.current) {
        const video = document.createElement('video');
        video.srcObject = stream;
        video.autoplay = true;
        video.muted = true;
        video.playsInline = true;
        videoRef.current = video;
        
        const playVideo = async () => {
          try {
            await video.play();
            console.log('‚úÖ Video element playing');
          } catch (err) {
            console.error('‚ö†Ô∏è Auto-play blocked, will play on user interaction:', err);
          }
        };
        
        video.addEventListener('loadedmetadata', () => {
          console.log('‚úÖ Video metadata loaded:', video.videoWidth, 'x', video.videoHeight);
          playVideo();
        }, { once: true });
        
        if (video.readyState >= 1) {
          playVideo();
        }
      } else {
        videoRef.current.srcObject = stream;
        if (videoRef.current.readyState >= 1) {
          videoRef.current.play().catch(err => {
            console.warn('Video play warning:', err);
          });
        }
      }
      
      if (canvasRef.current && croppedStreamRef.current) {
        croppedStreamRef.current.getTracks().forEach(track => track.stop());
        croppedStreamRef.current = null;
        setCroppedStream(null);
      }
      
      if (!canvasRef.current) {
        const canvas = document.createElement('canvas');
        canvas.style.display = 'none';
        document.body.appendChild(canvas);
        canvasRef.current = canvas;
      }

      const handleTrackEnded = () => {
        console.warn('‚ö†Ô∏è Screen share ended by user');
        setError('Screen share ended. Please restart stream.');
        cleanupWebRTC();
      };

      const handleMetadataLoaded = () => {
        if (videoRef.current) {
          const { videoWidth, videoHeight } = videoRef.current;
          console.log('‚úÖ Video metadata loaded:', videoWidth, 'x', videoHeight);
          
          if (!cropSettingsRef.current) {
            streamRef.current = stream;
            setScreenStream(stream);
          }
        }
      };

      trackEndedHandlerRef.current = handleTrackEnded;
      metadataHandlerRef.current = handleMetadataLoaded;

      const videoTrack = stream.getVideoTracks()[0];
      if (videoTrack && trackEndedHandlerRef.current) {
        videoTrack.addEventListener('ended', trackEndedHandlerRef.current);
        (videoTrack as any)._endedHandler = trackEndedHandlerRef.current;
      }

      if (videoRef.current && metadataHandlerRef.current) {
        videoRef.current.addEventListener('loadedmetadata', metadataHandlerRef.current, { once: true });
      }

      streamRef.current = stream;
      setScreenStream(stream);

      streamIdRef.current = `stream-${Date.now()}-${authState.user?.id || 'admin'}`;

      setIsStreaming(true);
      setIsBroadcasting(false);
      setIsCropReady(false);
      showNotification('‚úÖ Screen capture started! Please select crop area or skip to start streaming.', 'success');

    } catch (err) {
      console.error('‚ùå Error starting screen share:', err);
      const errorMessage = (err as Error).message;
      if (errorMessage.includes('Permission denied')) {
        setError('Screen share permission was denied. Please allow screen sharing and try again.');
      } else {
        setError(`Failed to start screen share: ${errorMessage}`);
      }
      showNotification(`Failed to start screen share: ${errorMessage}`, 'error');
      cleanupWebRTC();
    } finally {
      setIsInitializing(false);
    }
  }, [isStreaming, isInitializing, sendWebSocketMessage, authState.user?.id, showNotification, cleanupWebRTC]);

  const stopWebRTCScreenShare = useCallback(() => {
    console.log('üõë Stopping WebRTC screen share...');
    if (authState.user?.id) {
      sendWebSocketMessage({
        type: 'webrtc:signal',
        data: { type: 'stream-stop', from: authState.user.id },
      });
    }
    showNotification('Screen sharing stopped', 'info');
    cleanupWebRTC();
  }, [sendWebSocketMessage, authState.user?.id, showNotification, cleanupWebRTC]);
  
  // Effect to handle incoming WebSocket signals
  useEffect(() => {
    const handleNewViewer = (event: Event) => {
      const detail = (event as CustomEvent).detail;
      const clientId = detail.from;
      
      console.log('‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ');
      console.log('üÜï [ADMIN] New viewer notification received');
      console.log('üÜï [ADMIN] Viewer clientId:', clientId);
      console.log('üÜï [ADMIN] Broadcasting status:', isBroadcasting);
      console.log('üÜï [ADMIN] Streaming status:', isStreaming);
      console.log('‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ');
      
      if (peerConnectionsRef.current.has(clientId)) {
        console.log(`‚ö†Ô∏è [ADMIN] Already have connection for ${clientId}, skipping`);
        return;
      }
      
      const currentStream = streamRef.current;
      const hasStream = currentStream && currentStream.getVideoTracks().length > 0;
      
      console.log('üÜï [ADMIN] Stream check:', {
        hasStream: !!currentStream,
        videoTracks: currentStream?.getVideoTracks().length || 0,
        isBroadcasting,
        isStreaming
      });
      
      if (hasStream && isBroadcasting) {
        const tracks = currentStream.getVideoTracks();
        const hasLiveTrack = tracks.length > 0 && tracks[0].readyState === 'live' && tracks[0].enabled;
        const trackMuted = tracks.length > 0 ? (tracks[0] as any).muted : false;
        
        console.log('üÜï [ADMIN] Track status:', {
          trackCount: tracks.length,
          trackState: tracks[0]?.readyState,
          trackEnabled: tracks[0]?.enabled,
          trackMuted: trackMuted,
          hasLiveTrack
        });
        
        if (hasLiveTrack) {
          if (trackMuted) {
            console.warn(`‚ö†Ô∏è [ADMIN] Track is MUTED! This will prevent frames from being sent to ${clientId}`);
            console.warn(`‚ö†Ô∏è [ADMIN] Check browser/system settings - track might be muted at source`);
          }
          console.log(`‚úÖ [ADMIN] Stream ready for ${clientId}, creating offer...`);
          console.log(`‚úÖ [ADMIN] Calling createAndSendOffer(${clientId}) in 100ms...`);
          setTimeout(() => {
            console.log(`‚úÖ [ADMIN] Now calling createAndSendOffer(${clientId})...`);
            createAndSendOffer(clientId);
          }, 100);
        } else {
          console.log(`‚è≥ [ADMIN] Queued viewer ${clientId} - stream track not live yet (state: ${tracks[0]?.readyState}, enabled: ${tracks[0]?.enabled})`);
          pendingViewersRef.current.add(clientId);
        }
      } else {
        console.log(`‚è≥ [ADMIN] Queued viewer ${clientId} - waiting for stream (hasStream: ${hasStream}, isBroadcasting: ${isBroadcasting})`);
        console.log(`‚è≥ [ADMIN] Stream details:`, {
          hasStream: !!currentStream,
          streamTracks: currentStream?.getVideoTracks().length || 0,
          isBroadcasting,
          isStreaming
        });
        pendingViewersRef.current.add(clientId);
      }
    };

    const handleAnswer = (event: Event) => {
      const detail = (event as CustomEvent).detail;
      const clientId = detail.from;
      console.log('[LOG] handleAnswer called for clientId:', clientId);
      const pc = peerConnectionsRef.current.get(clientId);
      if (pc) {
        console.log(`[LOG] Received answer from ${clientId}`);
        pc.setRemoteDescription(new RTCSessionDescription({ type: 'answer', sdp: detail.sdp }))
          .catch(err => console.error('Error setting remote description:', err));
      }
    };

    const handleIceCandidate = (event: Event) => {
      const detail = (event as CustomEvent).detail;
      const clientId = detail.from;
      console.log('[LOG] handleIceCandidate called for clientId:', clientId);
      const pc = peerConnectionsRef.current.get(clientId);
      if (pc && detail.candidate) {
        console.log(`[LOG] Received ICE candidate from ${clientId}`);
        pc.addIceCandidate(new RTCIceCandidate(detail.candidate))
          .catch(err => console.error('Error adding ICE candidate:', err));
      }
    };

    const handleViewerLeft = (event: Event) => {
      const detail = (event as CustomEvent).detail;
      const clientId = detail.from;
      console.log(`üëã Viewer left: ${clientId}`);
      const pc = peerConnectionsRef.current.get(clientId);
      if (pc) {
        pc.close();
        peerConnectionsRef.current.delete(clientId);
        console.log(`üîå Peer connection closed for left viewer: ${clientId}`);
      }
    };

    window.addEventListener('webrtc_answer_received', handleAnswer);
    window.addEventListener('webrtc_ice_candidate_received', handleIceCandidate);
    window.addEventListener('webrtc_new_viewer', handleNewViewer);
    window.addEventListener('webrtc_viewer_left', handleViewerLeft);

    // ‚úÖ CRITICAL: DO NOT cleanup event listeners - they must persist forever
    // The context is at app level and should never unmount
    // Removing cleanup ensures stream continues even during navigation
    // return () => { ... } - REMOVED for persistence
  }, [isBroadcasting, createAndSendOffer]);

  // ‚úÖ FIX: Process queued viewers when stream is ready
  useEffect(() => {
    if (!isBroadcasting || !isStreaming) {
      return;
    }

    const currentStream = streamRef.current;
    const videoTracks = currentStream?.getVideoTracks() || [];
    const hasLiveTrack = videoTracks.length > 0 && 
                         videoTracks[0].readyState === 'live' &&
                         videoTracks[0].enabled;
    
    if (hasLiveTrack && pendingViewersRef.current.size > 0) {
      // Process all pending viewers
      console.log('‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ');
      console.log(`üìã Processing ${pendingViewersRef.current.size} queued viewers...`);
      console.log('üìã Stream ready:', {
        hasStream: !!currentStream,
        videoTracks: videoTracks.length,
        trackState: videoTracks[0]?.readyState,
        trackEnabled: videoTracks[0]?.enabled
      });
      console.log('‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ');
      
      const pending = Array.from(pendingViewersRef.current);
      pendingViewersRef.current.clear();
      
      // Create offers for all queued viewers with staggered timing
      pending.forEach((clientId, index) => {
        setTimeout(() => {
          // Double-check stream is still ready
          const stream = streamRef.current;
          if (!stream) {
            console.warn(`‚ö†Ô∏è Stream lost for queued viewer ${clientId}, re-queuing...`);
            pendingViewersRef.current.add(clientId);
            return;
          }

          const tracks = stream.getVideoTracks();
          if (tracks.length === 0) {
            console.warn(`‚ö†Ô∏è Stream has no tracks for queued viewer ${clientId}, re-queuing...`);
            pendingViewersRef.current.add(clientId);
            return;
          }

          const track = tracks[0];
          if (track.readyState !== 'live' || !track.enabled) {
            console.warn(`‚ö†Ô∏è Stream track not live for queued viewer ${clientId}, re-queuing...`);
            pendingViewersRef.current.add(clientId);
            return;
          }

          console.log(`üìπ Creating offer for queued viewer ${clientId}`);
          createAndSendOffer(clientId);
        }, 100 * (index + 1)); // Stagger to avoid overwhelming
      });
    }
  }, [isBroadcasting, isStreaming, createAndSendOffer]); // ‚úÖ Add isStreaming to dependencies

  const pauseStream = useCallback(() => {
    // Implement pause logic if needed
    setIsPaused(true);
  }, []);

  const resumeStream = useCallback(() => {
    // Implement resume logic if needed
    setIsPaused(false);
  }, []);

  const value = {
    isStreaming,
    isPaused,
    isInitializing,
    isCropReady,
    error,
    startWebRTCScreenShare,
    stopWebRTCScreenShare,
    pauseStream,
    resumeStream,
    screenStream,
    originalStream,
    croppedStream,
    cropSettings,
    setCropSettings,
    confirmCropAndStart,
    skipCropAndStart,
    getVideoRef: () => videoRef.current,
    getCanvasRef: () => canvasRef.current,
  };

  return <AdminStreamContext.Provider value={value}>{children}</AdminStreamContext.Provider>;
};

